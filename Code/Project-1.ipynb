{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables and Justification\n",
    "\n",
    "## Y Variable \n",
    "\n",
    "**annual_base_pay**\n",
    "\n",
    "## X Variables\n",
    "\n",
    "**total_experience_years**\n",
    "\n",
    "The years of experience someone has can greatly impact their compensation as a result of the insight they bring through their experience so this variable is highly relevant to someone’s annual compensation.\n",
    "\n",
    "**employer_experience_years**\n",
    "\n",
    "Someone’s employer experience years are directly relevant to their skillset in a particular field, with employer experience years being defined as the years of experience someone has in a particular field or specific company, which can obviously have a significant impact on annual compensation.\n",
    "\n",
    "**signing_bonus**\n",
    "\n",
    "One's signing bonus could impact their initial compensation since the company provided a large portion up front resulting in a lower salary, so this relationship would be interesting to analyze.\n",
    "\n",
    "**annual_bonus & stock_value_bonus**\n",
    "\n",
    "Someone’s annual bonus and stock options can reduce their pay as a result of performance-based compensation so these variables relationship to salary will be interesting to analyze with respect to annual compensation.\n",
    "\n",
    "**location_state/province & location_country**\n",
    "\n",
    "These variables will allow us to analyze the impact of where someone lives/works on their salary enabling us to assess the impact of geographical factors on annual compensation.\n",
    "\n",
    "**job_title_category**\n",
    "\n",
    "This variable allows us to compare salaries across sectors in tech which is crucial to understanding the industry landscape.\n",
    "\n",
    "**job_title_rank**\n",
    "\n",
    "This variable will allow us to gauge the impact of seniority on annual compensation which is important in terms of understanding how long it could take to reach different levels of compensation in in various sectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "T_S = pd.read_csv(r\"C:\\Desktop\\Rotman Commerce\\Year 3\\Sem 2\\ECO 225\\Data\\Tech Salaries\\salaries_clean.csv\")\n",
    "\n",
    "# sets pandas to display floats in regular notation\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Columns to analyze\n",
    "columns_to_check = ['total_experience_years', 'employer_experience_years', 'annual_base_pay', 'signing_bonus', 'annual_bonus', 'stock_value_bonus']\n",
    "\n",
    "# Convert columns to numeric\n",
    "for col in columns_to_check:\n",
    "    T_S[col] = pd.to_numeric(T_S[col], errors='coerce')  # Convert to numeric\n",
    "\n",
    "# Drop rows with NaN in relevant columns\n",
    "T_S = T_S.dropna(subset=columns_to_check)\n",
    "\n",
    "# Initialize an empty DataFrame for outliers\n",
    "outliers = pd.DataFrame()\n",
    "\n",
    "# Loop through each column to calculate outliers\n",
    "for col in columns_to_check:\n",
    "    Q1 = T_S[col].quantile(0.25)  # 25th percentile\n",
    "    Q3 = T_S[col].quantile(0.75)  # 75th percentile\n",
    "    IQR = Q3 - Q1                 # Interquartile range\n",
    "\n",
    "    # Calculate bounds\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Identify outliers\n",
    "    col_outliers = T_S[(T_S[col] < lower_bound) | (T_S[col] > upper_bound)]\n",
    "    outliers = pd.concat([outliers, col_outliers])  # Add to outliers DataFrame\n",
    "\n",
    "# Drop duplicates in case of overlap across columns\n",
    "outliers = outliers.drop_duplicates()\n",
    "\n",
    "# Create a non-outliers DataFrame\n",
    "non_outliers = T_S[~T_S.index.isin(outliers.index)]\n",
    "\n",
    "def analyze(DataFrame, columns=None):\n",
    "    \"\"\"\n",
    "    Analyze a dataframe and output basic statistics in the describe.() method in a addition to excess kurtosis, skewness and the results of\n",
    "    normality tests for both kurtosis and skewness\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select specific columns to analyze if provided, otherwise use all numeric columns\n",
    "    if columns is not None:\n",
    "        DataFrame = DataFrame[columns]\n",
    "    else:\n",
    "        DataFrame = DataFrame.select_dtypes(include=[np.number])  # Select numeric columns only\n",
    "\n",
    "    # Calculate the length of the dataset\n",
    "    length = len(DataFrame)\n",
    "\n",
    "    # Basic statistics\n",
    "    stats = DataFrame.describe()\n",
    "\n",
    "    # Skewness and excess kurtosis\n",
    "    skewness = DataFrame.skew()\n",
    "    kurtosis = DataFrame.kurtosis()\n",
    "\n",
    "    # Test for normality of skewness\n",
    "    Norm_Skew = skewness.apply(lambda x: 'Normal' if abs(x * np.sqrt(length / 6)) <= 1.96 else 'Not Normal')\n",
    "\n",
    "    # Test for normality of kurtosis\n",
    "    Norm_Kurt = kurtosis.apply(lambda x: 'Normal' if abs(x * np.sqrt(length / 24)) <= 1.96 else 'Not Normal')\n",
    "\n",
    "    # Combine skewness, kurtosis, and normality into a DataFrame\n",
    "    p_kurt_skew = pd.concat([skewness, kurtosis, Norm_Skew, Norm_Kurt], axis=1)\n",
    "    p_kurt_skew.columns = ['Skewness', 'Excess Kurtosis', 'Norm_Skew', 'Norm_Kurt']\n",
    "\n",
    "    # Combine with basic statistics\n",
    "    p_stats = pd.concat([stats, p_kurt_skew.transpose()])\n",
    "\n",
    "    return p_stats\n",
    "\n",
    "analyze(non_outliers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_S.groupby(['location_state', 'location_country']).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_S.groupby(['job_title_category', 'job_title_rank']).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histrogram to display the annual_base_pay distribution \n",
    "non_outliers['annual_base_pay'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
